{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPzeozoFZmGh1e2Frd08Bke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesgolden1/llms-are-llms/blob/main/notebooks/gemma_3/gemma_3_12B_locally_linear_steering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = '1'\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Execute commands - os.system shows output in real-time by default\n",
        "os.system('git clone https://github.com/jamesgolden1/llms-are-llms.git')\n",
        "os.chdir('llms-are-llms')\n",
        "os.system('pip install -r requirements.txt --no-deps')\n",
        "# os.system(f'python -u run_detached_jacobian.py --hf_token {os.environ[\"HF_TOKEN\"]} --model_name \"gemma-3-4b\" --text \"The lightning\"')\n",
        "\n",
        "# concept to inject into response\n",
        "text = \"The bridge is the Golden\"\n",
        "model_name = \"gemma-3-12b\"\n",
        "%run run_detached_jacobian.py --text $text --hf_token os.environ[\"HF_TOKEN\"] --model_name $model_name --dtype \"bfloat16\""
      ],
      "metadata": {
        "id": "qWoSBqCQ07cQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"I went to new york to see the \", tlen=28, lsplit=33, lambda_w=0.17)"
      ],
      "metadata": {
        "id": "0o7pAwnr1_e8",
        "outputId": "0fba02da-71e8-48ab-a5e6-869bf027ca2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "th\n",
            " anniversary\n",
            " of\n",
            " the\n",
            " Broadway\n",
            " show\n",
            ",\n",
            " \"\n",
            "The\n",
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            " Bridge\n",
            ".\n",
            " It\n",
            " was\n",
            " a\n",
            " great\n",
            " show\n",
            ".\n",
            " I\n",
            " was\n",
            " also\n",
            " in\n",
            " a\n",
            " \n",
            "('I went to new york to see the 10th anniversary of the Broadway show, \"The '\n",
            " 'Golden Gate Bridge Bridge. It was a great show. I was also in a ')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I went to new york to see the 10th anniversary of the Broadway show, \"The Golden Gate Bridge Bridge. It was a great show. I was also in a '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"I went to new york to see the\", tlen=28, lsplit=33, lambda_w=0.)#17)"
      ],
      "metadata": {
        "id": "2UDQEJkp4Udw",
        "outputId": "e7219046-6c72-4112-ed12-ee191444853c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer layer 33\n",
            "model_forward_output:  tensor([ 1.0469,  0.6406,  0.3809,  ..., -1.7656, -3.0469,  0.0840],\n",
            "       device='cuda:0', dtype=torch.bfloat16)\n",
            "Computing SVD for token position 0\n",
            "Token 0, U 0, mag=2.14:  bridge  bridges  Bridge bridge Bridge  Bridges  BRIDGE æ¡¥\n",
            " broad\n",
            "way\n",
            " show\n",
            " \"\n",
            "W\n",
            "icked\n",
            "\"\n",
            " and\n",
            " I\n",
            " had\n",
            " a\n",
            " wonderful\n",
            " time\n",
            ".\n",
            " The\n",
            " show\n",
            " was\n",
            " amazing\n",
            " and\n",
            " the\n",
            " theater\n",
            " was\n",
            " beautiful\n",
            ".\n",
            " I\n",
            " would\n",
            " highly\n",
            " recommend\n",
            "('I went to new york to see the broadway show \"Wicked\" and I had a wonderful '\n",
            " 'time. The show was amazing and the theater was beautiful. I would highly '\n",
            " 'recommend')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I went to new york to see the broadway show \"Wicked\" and I had a wonderful time. The show was amazing and the theater was beautiful. I would highly recommend'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}