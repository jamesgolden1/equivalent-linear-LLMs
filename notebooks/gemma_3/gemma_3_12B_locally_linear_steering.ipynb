{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNUq7Sw71gV7pV9nJmV7COE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "335bc64ace2c4196bf15729ed07f4947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_553a3bcd31654b6ea9d2c6a0b1bde190",
              "IPY_MODEL_ebcff45245eb4ecbad60d02d21b041bd",
              "IPY_MODEL_752c4ecd9575460b9208005bc4c4ca06"
            ],
            "layout": "IPY_MODEL_10463ddf7bcb4f5884b73d5776ce24ac"
          }
        },
        "553a3bcd31654b6ea9d2c6a0b1bde190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e17454ac4e245a4826f2ac7cfd70f04",
            "placeholder": "​",
            "style": "IPY_MODEL_a92301bf60f346eeb32b632f4ead6d74",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ebcff45245eb4ecbad60d02d21b041bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b108adc8ce8a45389f157dbdde3f9ee1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d7456a20c964b558c8aee2c36f18563",
            "value": 5
          }
        },
        "752c4ecd9575460b9208005bc4c4ca06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59490b25c954af596cc2500cc81fddf",
            "placeholder": "​",
            "style": "IPY_MODEL_2c85927a1afc4150a787d5c54db701a8",
            "value": " 5/5 [00:00&lt;00:00, 13.16it/s]"
          }
        },
        "10463ddf7bcb4f5884b73d5776ce24ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e17454ac4e245a4826f2ac7cfd70f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92301bf60f346eeb32b632f4ead6d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b108adc8ce8a45389f157dbdde3f9ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d7456a20c964b558c8aee2c36f18563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f59490b25c954af596cc2500cc81fddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c85927a1afc4150a787d5c54db701a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesgolden1/llms-are-llms/blob/main/notebooks/gemma_3/gemma_3_12B_locally_linear_steering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install \"huggingface_hub[hf_transfer]\""
      ],
      "metadata": {
        "id": "yfOoWhFL_mOW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mRz9ZdpYeb3J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"]='1'\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GITHUB_TOKEN']=userdata.get('GITHUB_TOKEN')"
      ],
      "metadata": {
        "id": "3jsio4cYqU2b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://jamesgolden1:$GITHUB_TOKEN@github.com/jamesgolden1/llms-are-llms.git"
      ],
      "metadata": {
        "id": "BxwNRTeTq8aR",
        "outputId": "2c613567-da75-4e56-9186-cb2e93bf6b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llms-are-llms' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/llms-are-llms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q2ii5zer3_7",
        "outputId": "bd6acefa-2d63-4b9f-ab7c-12ca62d8f313"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llms-are-llms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from src.JacobianAnalyzer import *"
      ],
      "metadata": {
        "id": "nS_9_lzUvyJl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.JacobianAnalyzer import JacobianAnalyzer as JacobianAnalyzer"
      ],
      "metadata": {
        "id": "s3ZIImFTsnok"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.gemma_3.gemma_3_forward import model_forward"
      ],
      "metadata": {
        "id": "mAT2pAC1s12f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Jacobian Analysis\n",
        "%%time\n",
        "# %%writefile run_llama.py\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import argparse\n",
        "\n",
        "setattr(JacobianAnalyzer, 'model_forward', model_forward)\n",
        "\n",
        "run_all = False\n",
        "\n",
        "# Initialize the analyzer\n",
        "analyzer = JacobianAnalyzer(model_name=\"google/gemma-3-12b-it\")#\"google/gemma-3-4b-it\")\n",
        "\n",
        "# text = 'The Golden'\n",
        "# text = 'The Golden Gate'\n",
        "text = 'The bridge is the Golden'\n",
        "max_new_tokens=1\n",
        "temperature=1e-6\n",
        "\n",
        "# Generate output\n",
        "analyzer.generate(text, max_new_tokens, temperature);\n",
        "\n",
        "# # # Compute Jacobian\n",
        "analyzer.compute_jacobian()\n",
        "# analyzer.compute_jacobian_nonlinear()\n",
        "# analyzer.plot_jacobian_comparison(text,filename_png=\"fig3\")\n",
        "\n",
        "# # analyzer.compute_jacobian_row_col_norm(n_components=8)#, svs=1)\n",
        "# # analyzer.plot_singular_values(mode=\"row_col_vectors\",filename_png=\"fig4_col\")\n",
        "\n",
        "analyzer.compute_jacobian_svd(n_components=24, svs=1)\n",
        "# analyzer.plot_singular_values(title=\"SVD\",filename_png=\"fig4_svd\")\n",
        "\n",
        "# analyzer.plot_jacobian_image(filename_png=\"fig2\")\n",
        "\n",
        "if run_all:\n",
        "    layerlist=list(range(1,32))\n",
        "    # layerlist.extend([26,27])\n",
        "    analyzer.compute_jacobian_layers_svd(layerlist=layerlist,n_components=24,svs=8)#,filename=\"fig5_svd_layers_llama_3_2\")\n",
        "    analyzer.plot_singular_values(title=\"SVD Layers\",mode='singular_vectors_layers',key='layer',filename_png=\"fig5_svd_layers\")\n",
        "\n",
        "    analyzer.compute_jacobian_layers_svd(layerlist=layerlist,n_components=4,svs=2,key='mlp')#,filename=\"fig5_svd_layers_llama_3_2_mlp\")\n",
        "    analyzer.plot_singular_values(title=\"SVD MLP\",mode='singular_vectors_layers',key='mlp',filename_png=\"fig5_svd_mlp\")\n",
        "\n",
        "    analyzer.compute_jacobian_layers_svd(layerlist=layerlist,n_components=4,svs=2,key='attn')#,filename=\"fig5_svd_layers_llama_3_2_attn\")\n",
        "    analyzer.plot_singular_values(title=\"SVD Attn\",mode='singular_vectors_layers',key='attn',filename_png=\"fig5_svd_attn\")\n",
        "\n",
        "    analyzer.plot_path(filename_png=\"fig6_path\")\n",
        "    analyzer.plot_dimensionality(filename_png=\"fig6_dimensionality\")\n",
        "\n",
        "    analyzer.compute_jacobian_layers_svd(layerlist=layerlist,layer_mode='layerwise',n_components=4,svs=2)#,filename=\"fig5_svd_layers_llama_3_2\")\n",
        "    analyzer.plot_singular_values(title=\"SVD Layers\",mode='singular_vectors_layers_layerwise',key='layer',filename_png=\"fig5_svd_layers_layerwise\")\n",
        "\n",
        "    analyzer.compute_jacobian_layers_svd(layerlist=layerlist,layer_mode='layerwise',n_components=4,svs=2,key='mlp')#,filename=\"fig5_svd_layers_llama_3_2_mlp\")\n",
        "    analyzer.plot_singular_values(title=\"SVD MLP\",mode='singular_vectors_layers_layerwise',key='mlp',filename_png=\"fig5_svd_mlp_layerwise\")\n",
        "\n",
        "    analyzer.compute_jacobian_layers_svd(layerlist=layerlist,layer_mode='layerwise',n_components=4,svs=2,key='attn')#,filename=\"fig5_svd_layers_llama_3_2_attn\")\n",
        "    analyzer.plot_singular_values(title=\"SVD Attn\",mode='singular_vectors_layers_layerwise',key='attn',filename_png=\"fig5_svd_attn_layerwise\")\n",
        "\n",
        "    analyzer.plot_path(filename_png=\"fig6_dimensionality_layerwise\")\n",
        "\n",
        "# # if __name__ == \"__main__\":\n",
        "# #     main()"
      ],
      "metadata": {
        "id": "uZbxv6Ns17uw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "335bc64ace2c4196bf15729ed07f4947",
            "553a3bcd31654b6ea9d2c6a0b1bde190",
            "ebcff45245eb4ecbad60d02d21b041bd",
            "752c4ecd9575460b9208005bc4c4ca06",
            "10463ddf7bcb4f5884b73d5776ce24ac",
            "6e17454ac4e245a4826f2ac7cfd70f04",
            "a92301bf60f346eeb32b632f4ead6d74",
            "b108adc8ce8a45389f157dbdde3f9ee1",
            "3d7456a20c964b558c8aee2c36f18563",
            "f59490b25c954af596cc2500cc81fddf",
            "2c85927a1afc4150a787d5c54db701a8"
          ]
        },
        "outputId": "5cf67c06-a20f-4755-c76d-5123718cc533"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "335bc64ace2c4196bf15729ed07f4947"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1e-06` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_forward_error: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', dtype=torch.bfloat16,\n",
            "       grad_fn=<SubBackward0>)\n",
            "detached Jacobian error: tensor([-0.0156,  0.0742,  0.0000,  ...,  0.0083,  0.0078,  0.0391],\n",
            "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SubBackward0>)\n",
            "Computing SVD for token position 0\n",
            "Computing SVD for token position 1\n",
            "Computing SVD for token position 2\n",
            "Computing SVD for token position 3\n",
            "Computing SVD for token position 4\n",
            "Computing SVD for token position 5\n",
            "Token 0, U SV 0:  Gate  Bridge  State Gate  Gates  Bay  Falls -\n",
            "Token 1, U SV 0:  Gate  Bridge -  G Gate  State  Gates \n",
            "Token 2, U SV 0:  Gate Gate  Bridge  Fair  Ears  Gates  State  Ponte\n",
            "Token 3, U SV 0:  Gate Gate  State  Bridge  Falls  Spike  Jubilee  Bay\n",
            "Token 4, U SV 0:  Gate  State Gate  Spike  Anniversary  Jubilee  Quadr  Ears\n",
            "Token 5, U SV 0:  Spike  Gate  State  Rule rod  Bau weiser thread\n",
            "CPU times: user 1min 26s, sys: 7.36 s, total: 1min 34s\n",
            "Wall time: 42.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(analyzer.model.model.layers)"
      ],
      "metadata": {
        "id": "-AtLHTAB_xnI",
        "outputId": "725bff48-b6a1-4bbb-fdf0-f341de413817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", tlen=16, lsplit=33, lambda_w=0.16)"
      ],
      "metadata": {
        "id": "KmUj8hLJD9UO",
        "outputId": "a0ef8b40-3e35-46e5-b6ae-e92d517a010a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer layer 33\n",
            "Computing SVD for token position 0\n",
            "Token 0, U SV 0:  bridge  bridges    and  water  one  a  state\n",
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            " in\n",
            " San\n",
            " Francisco\n",
            ".\n",
            " I\n",
            " used\n",
            " a\n",
            " Golden\n",
            " Gate\n",
            " Gate\n",
            " Bridge\n",
            " and\n",
            " a\n",
            "('Here is a painting of the Golden Gate Bridge in San Francisco. I used a '\n",
            " 'Golden Gate Gate Bridge and a')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a painting of the Golden Gate Bridge in San Francisco. I used a Golden Gate Gate Bridge and a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", tlen=28, lsplit=33, lambda_w=0.12)"
      ],
      "metadata": {
        "id": "Xl_DiUEwEXS7",
        "outputId": "ff8f99e8-8071-46e5-9f27-57c637f5ee4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            ".\n",
            " I\n",
            " used\n",
            " a\n",
            " watercolor\n",
            " and\n",
            " a\n",
            " watercolor\n",
            " brush\n",
            ".\n",
            " I\n",
            " also\n",
            " used\n",
            " a\n",
            " white\n",
            " and\n",
            " a\n",
            " black\n",
            " paint\n",
            ".\n",
            " I\n",
            " used\n",
            " a\n",
            " blue\n",
            " and\n",
            "('Here is a painting of the Golden Gate Bridge. I used a watercolor and a '\n",
            " 'watercolor brush. I also used a white and a black paint. I used a blue and')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a painting of the Golden Gate Bridge. I used a watercolor and a watercolor brush. I also used a white and a black paint. I used a blue and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"I went to arizona to see the\", tlen=28, lsplit=33, lambda_w=0.17)"
      ],
      "metadata": {
        "id": "hbnQMD7OEg9Z",
        "outputId": "8b900469-e07a-45f9-d3c7-bca6ada454b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            ".\n",
            "\n",
            "I\n",
            " went\n",
            " to\n",
            " a\n",
            " Arizona\n",
            " to\n",
            " see\n",
            " the\n",
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            ".\n",
            "\n",
            "I\n",
            " went\n",
            " to\n",
            " California\n",
            " to\n",
            " see\n",
            " the\n",
            " Golden\n",
            " Bridge\n",
            ".\n",
            "('I went to arizona to see the Golden Gate Bridge.\\n'\n",
            " '\\n'\n",
            " 'I went to a Arizona to see the Golden Gate Bridge.\\n'\n",
            " '\\n'\n",
            " 'I went to California to see the Golden Bridge.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I went to arizona to see the Golden Gate Bridge.\\n\\nI went to a Arizona to see the Golden Gate Bridge.\\n\\nI went to California to see the Golden Bridge.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"I went to new york to see the \", tlen=28, lsplit=33, lambda_w=0.17)"
      ],
      "metadata": {
        "id": "-VTOxndGEuJU",
        "outputId": "16ad34d9-2dc8-4c7c-e536-8918c9b84cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "th\n",
            " anniversary\n",
            " of\n",
            " the\n",
            " Broadway\n",
            " show\n",
            ",\n",
            " \"\n",
            "The\n",
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            " Bridge\n",
            ".\n",
            " It\n",
            " was\n",
            " a\n",
            " great\n",
            " show\n",
            ".\n",
            " I\n",
            " was\n",
            " also\n",
            " in\n",
            " a\n",
            " \n",
            "('I went to new york to see the 10th anniversary of the Broadway show, \"The '\n",
            " 'Golden Gate Bridge Bridge. It was a great show. I was also in a ')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I went to new york to see the 10th anniversary of the Broadway show, \"The Golden Gate Bridge Bridge. It was a great show. I was also in a '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", tlen=16, lsplit=43, lambda_w=0.24)"
      ],
      "metadata": {
        "id": "5cRQB5H3D2Qd",
        "outputId": "292c060f-7f44-4867-f20e-c8e77d8bcf7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            " iconic\n",
            ",\n",
            "('Here is a painting of the iconic, iconic, iconic, iconic, iconic, iconic, '\n",
            " 'iconic, iconic,')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a painting of the iconic, iconic, iconic, iconic, iconic, iconic, iconic, iconic,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", tlen=16, lsplit=43, lambda_w=0.24)"
      ],
      "metadata": {
        "id": "ltrxI6FqDqbw",
        "outputId": "1c5b84f4-ba89-4537-d8a4-e8d7acd7cadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Gate\n",
            " Bridge\n",
            ".\n",
            " I\n",
            " painted\n",
            " this\n",
            " in\n",
            " \n",
            " Gate\n",
            " Bridge\n",
            ",\n",
            " California\n",
            ".\n",
            "<start_of_image>\n",
            "  \n",
            "I\n",
            "('Here is a painting of the Gate Bridge. I painted this in  Gate Bridge, '\n",
            " 'California.<start_of_image>  I')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a painting of the Gate Bridge. I painted this in  Gate Bridge, California.<start_of_image>  I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", tlen=16, lsplit=43, lambda_w=0.2)"
      ],
      "metadata": {
        "id": "SymrKC0qC-zE",
        "outputId": "011c8946-3904-4b91-ae42-c0506f4a96f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Great\n",
            " Gate\n",
            " of\n",
            " King\n",
            " Gate\n",
            ",\n",
            " a\n",
            " gate\n",
            " of\n",
            " the\n",
            " Forbidden\n",
            " City\n",
            " in\n",
            " Beijing\n",
            ",\n",
            " China\n",
            "('Here is a painting of the Great Gate of King Gate, a gate of the Forbidden '\n",
            " 'City in Beijing, China')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a painting of the Great Gate of King Gate, a gate of the Forbidden City in Beijing, China'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is \", tlen=16, lsplit=43, lambda_w=0.34)"
      ],
      "metadata": {
        "id": "1poaNC6h4n2l",
        "outputId": "7febbd64-231e-41e7-88fe-ad806eae2f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " is\n",
            " a\n",
            " \n",
            "1\n",
            "0\n",
            "-\n",
            "year\n",
            " plan\n",
            " for\n",
            " a\n",
            " \n",
            "1\n",
            "-\n",
            " acre\n",
            " property\n",
            " in\n",
            "'Here is  is a 10-year plan for a 1- acre property in'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is  is a 10-year plan for a 1- acre property in'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", tlen=16, lsplit=43, lambda_w=0.2)"
      ],
      "metadata": {
        "id": "03e8Zr8EClDT",
        "outputId": "11ba48e2-6201-4b33-c832-7863cf80e9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " bridge\n",
            " in\n",
            " the\n",
            " park\n",
            ".\n",
            "\n",
            "<start_of_image>\n",
            "\n",
            "I\n",
            " have\n",
            " been\n",
            " working\n",
            " on\n",
            " this\n",
            " painting\n",
            " for\n",
            "('Here is a painting of the bridge in the park.\\n'\n",
            " '\\n'\n",
            " '<start_of_image>\\n'\n",
            " '\\n'\n",
            " 'I have been working on this painting for')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a painting of the bridge in the park.\\n\\n<start_of_image>\\n\\nI have been working on this painting for'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(new_text=\"Here is a painting of the\", lambda_w=0.12)"
      ],
      "metadata": {
        "id": "vGzUQuKY4q-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def model_forward(self, embeds, lstart=0, lsplit=None, key='layer'):\n",
        "        \"\"\"\n",
        "        Forward pass through model layers with linearization for Jacobian analysis.\n",
        "\n",
        "        Args:\n",
        "            embeds: Input embeddings tensor of shape (batch_size, seq_length, hidden_size)\n",
        "            lstart (int): Starting layer index\n",
        "            lsplit (int): Number of layers to process (if None, process all layers)\n",
        "            key (str): Return type - 'layer' for final layer output, 'attn' for attention output,\n",
        "                      'mlp' for MLP output, or various input keys\n",
        "\n",
        "        Returns:\n",
        "            Hidden states tensor after processing specified layers\n",
        "        \"\"\"\n",
        "        outdict = {}\n",
        "\n",
        "        if lsplit is None:\n",
        "            lsplit = len(self.model.model.layers)\n",
        "\n",
        "        # Get batch size and sequence length\n",
        "        batch_size, seq_length = embeds.shape[:2]\n",
        "\n",
        "        # Create position IDs\n",
        "        position_ids = torch.arange(seq_length, device=embeds.device).unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        # Generate position embeddings for rotary attention\n",
        "        cos, sin = self.model.model.rotary_emb(embeds, position_ids)\n",
        "        position_embeddings = (cos, sin)\n",
        "\n",
        "        # Create cache position for tracking position in sequence\n",
        "        cache_position = torch.arange(seq_length, device=embeds.device)\n",
        "\n",
        "        # Create basic attention mask (all ones)\n",
        "        attention_mask = torch.ones(batch_size, seq_length, dtype=torch.float, device=embeds.device)\n",
        "\n",
        "        # Generate causal mask\n",
        "        causal_mask = self.model.model._update_causal_mask(\n",
        "            attention_mask,\n",
        "            embeds,\n",
        "            cache_position,\n",
        "            None,  # past_key_values\n",
        "            False  # output_attentions\n",
        "        )\n",
        "\n",
        "        # Process through layers\n",
        "        hidden_states = embeds\n",
        "\n",
        "        for li in range(lstart, lsplit):\n",
        "            # Store input states if requested\n",
        "            if key == 'layer_input':\n",
        "                outdict['layer_input'] = hidden_states\n",
        "            elif key == 'attn_input':\n",
        "                outdict['attn_input'] = hidden_states\n",
        "\n",
        "            # Store residual for skip connection\n",
        "            residual = hidden_states\n",
        "\n",
        "            # Apply input layer normalization\n",
        "            hidden_states = self.model.model.layers[li].input_layernorm(hidden_states)\n",
        "\n",
        "            # Self Attention\n",
        "            attn_output, _ = self.model.model.layers[li].self_attn(\n",
        "                hidden_states=hidden_states,\n",
        "                attention_mask=causal_mask,\n",
        "                position_ids=position_ids,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False,\n",
        "                use_cache=False,\n",
        "                cache_position=cache_position,\n",
        "                position_embeddings=position_embeddings\n",
        "            )\n",
        "\n",
        "            # Save attention output if requested\n",
        "            if key == 'attn':\n",
        "                if li == lsplit - 1:\n",
        "                    attn_output = self.model.model.norm(attn_output)\n",
        "                outdict['attn'] = attn_output\n",
        "\n",
        "            # Add residual connection\n",
        "            hidden_states = residual + attn_output\n",
        "\n",
        "            # Store residual for MLP block\n",
        "            residual = hidden_states\n",
        "\n",
        "            # Apply post attention layer normalization\n",
        "            hidden_states = self.model.model.layers[li].post_attention_layernorm(hidden_states)\n",
        "\n",
        "            if key == 'mlp_input':\n",
        "                outdict['mlp_input'] = hidden_states\n",
        "\n",
        "            # Apply MLP\n",
        "            mlp_output = self.model.model.layers[li].mlp(hidden_states)\n",
        "\n",
        "            # Save MLP output if requested\n",
        "            if key == 'mlp':\n",
        "                if li == lsplit - 1:\n",
        "                    mlp_output = self.model.model.norm(mlp_output)\n",
        "                outdict['mlp'] = mlp_output\n",
        "\n",
        "            # Add residual connection\n",
        "            hidden_states = residual + mlp_output\n",
        "\n",
        "        # Apply final normalization if we processed all layers\n",
        "        if key != \"layer_input\" and li == lsplit - 1:\n",
        "            hidden_states = self.model.model.norm(hidden_states)\n",
        "\n",
        "        # Store final layer output\n",
        "        outdict['layer'] = hidden_states\n",
        "\n",
        "        # Return the appropriate output based on key\n",
        "        if key in [\"layer_input\", \"attn_input\", \"mlp_input\"]:\n",
        "            return outdict[key]\n",
        "        else:\n",
        "            return outdict[key][0, -1]"
      ],
      "metadata": {
        "id": "qlW-6PUr5Vx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}