{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPJlQLwNIY/wgcsfXQs7plA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesgolden1/llms-are-llms/blob/main/notebooks/llama_3/llama_3_1_8B_locally_linear_steering_operator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# !pip install -U bitsandbytes\n",
        "!pip install \"huggingface_hub[hf_transfer]\""
      ],
      "metadata": {
        "id": "yfOoWhFL_mOW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers==4.51.3 --upgrade --force-reinstall"
      ],
      "metadata": {
        "id": "WvEhimtj1zNT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mRz9ZdpYeb3J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"]='1'\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GITHUB_TOKEN']=userdata.get('GITHUB_TOKEN')"
      ],
      "metadata": {
        "id": "3jsio4cYqU2b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://jamesgolden1:$GITHUB_TOKEN@github.com/jamesgolden1/llms-are-llms.git"
      ],
      "metadata": {
        "id": "BxwNRTeTq8aR",
        "outputId": "249b083b-c581-4466-f36d-95e40d66eede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llms-are-llms' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content"
      ],
      "metadata": {
        "id": "khlyiUY4d7Js"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf llms-are-llms/"
      ],
      "metadata": {
        "id": "1gFwuprCd68h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd llms-are-llms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q2ii5zer3_7",
        "outputId": "c79c89d5-2aab-4772-d949-6c258137ce9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llms-are-llms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.JacobianAnalyzer import *"
      ],
      "metadata": {
        "id": "nS_9_lzUvyJl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.JacobianAnalyzer import JacobianAnalyzer as JacobianAnalyzer"
      ],
      "metadata": {
        "id": "s3ZIImFTsnok"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from models.llama_3.llama_3_forward import model_forward"
      ],
      "metadata": {
        "id": "mAT2pAC1s12f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls models/llama_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHtcyYMz3s75",
        "outputId": "fddc2efb-60f4-4f20-b351-551dfb045250"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modeling_llama_locally_linear.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Jacobian Analysis\n",
        "%%time\n",
        "# %%writefile run_llama.py\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import argparse\n",
        "\n",
        "# setattr(JacobianAnalyzer, 'model_forward', model_forward)\n",
        "\n",
        "# Initialize the analyzer\n",
        "analyzer = JacobianAnalyzer(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")\n",
        "run_all = False\n",
        "\n",
        "# text = 'The Golden'\n",
        "# text = 'The bridge is the'#\n",
        "text = 'The bridge out of Marin is the Golden'\n",
        "max_new_tokens=1\n",
        "temperature=1e-6\n",
        "\n",
        "# Generate output\n",
        "analyzer.generate(text, max_new_tokens, temperature);\n",
        "\n",
        "# # # Compute Jacobian\n",
        "analyzer.compute_jacobian()\n",
        "# analyzer.compute_jacobian_nonlinear()\n",
        "# analyzer.plot_jacobian_comparison(text,filename_png=\"fig3\")\n",
        "\n",
        "# analyzer.compute_jacobian_row_col_norm(n_components=8)#, svs=1)\n",
        "# analyzer.plot_singular_values(mode=\"row_col_vectors\",filename_png=\"fig4_col\")\n",
        "\n",
        "analyzer.compute_jacobian_svd(n_components=8, svs=1, token_list=list(range(analyzer.embeds.shape[1])))\n",
        "# analyzer.plot_singular_values(filename_png=\"fig4_svd\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "9ec340c64611404da6607f2d787a4202",
            "37bb59c65ecb4d099af7cc74fa287a9d",
            "29cea4f563ef41e186dce82f0f05bd43",
            "23be4ede58e14cebaaab5d6aef67fd47",
            "71e3d1f5688b45ddac986044226aa392",
            "2417d3bf8f2b49d8b3454363e3db7a99",
            "e4957b415cb644b9816ff380181eabc1",
            "c346aacb64d94328a391e5805b30a0b7",
            "8f3c7a535740446d90661b647d062cbb",
            "ac0657cfa7e14fbab8a5709f3178e90e",
            "6f5e0c115d0845dd8e392d833920d08f"
          ]
        },
        "id": "oRvuOY8uby6A",
        "outputId": "fb8adaae-0d06-4f9e-a685-99a1c7e53309"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ec340c64611404da6607f2d787a4202"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_forward_error: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', dtype=torch.bfloat16,\n",
            "       grad_fn=<SubBackward0>)\n",
            "detached Jacobian error: tensor([ 0.0117, -0.0312,  0.0195,  ..., -0.0469,  0.0078,  0.0312],\n",
            "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SubBackward0>)\n",
            "Computing SVD for token position 0\n",
            "Computing SVD for token position 1\n",
            "Computing SVD for token position 2\n",
            "Computing SVD for token position 3\n",
            "Computing SVD for token position 4\n",
            "Computing SVD for token position 5\n",
            "Computing SVD for token position 6\n",
            "Computing SVD for token position 7\n",
            "Computing SVD for token position 8\n",
            "Token 0, U 0, mag=482.96:  Gate  gate  Horn  Nug Gate eye  Arrow  Lantern\n",
            "Token 1, U 0, mag=71.18:  Gate  Gateway   -G   State ...  G\n",
            "Token 2, U 0, mag=133.61:  Gate -G     Gateway  G ... .\n",
            "Token 3, U 0, mag=75.26:  Gate -G  Gateway  State  G ...  gate \n",
            "Token 4, U 0, mag=59.32:  Gate  Gateway -G Gate  gate  State   G\n",
            "Token 5, U 0, mag=98.65:  Gate  -G Gate  Gateway gate  gate ...\n",
            "Token 6, U 0, mag=64.31:  Gate -G  Gateway  State Gate  gate  G \n",
            "Token 7, U 0, mag=83.35:  Gate  State  Gateway Gate -G  gate  G \n",
            "Token 8, U 0, mag=182.14:  Gate  State Gate -G  gate  Gateway  G \n",
            "CPU times: user 1min 7s, sys: 6 s, total: 1min 13s\n",
            "Wall time: 30.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.model_forward(analyzer.embeds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v636vsg1tZjt",
        "outputId": "385c3e9c-260b-494b-b2af-7cc4804913cb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5898,  2.6719, -0.8633,  ..., -3.1094,  0.6914, -1.6641],\n",
              "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6o4xLXZNh0Ax"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsplit = 22\n",
        "analyzer.model_forward(analyzer.model_forward(analyzer.embeds,lsplit=lsplit,key='layer_input'),lstart=lsplit-1)-analyzer.model_forward(analyzer.embeds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U-EyCbktRLh",
        "outputId": "b78ff410-412e-47db-d78b-018d581221be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', dtype=torch.bfloat16,\n",
              "       grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(tlen=34,new_text=\"I'm going to arizona to see the\", lsplit = 22, lambda_w=0.5065)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "c35qZ_-I5pLT",
        "outputId": "da4a0f83-d8f5-48bb-c65d-f79df9530f40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Grand\n",
            " Canyon\n",
            ",\n",
            " and\n",
            " I\n",
            "'m\n",
            " planning\n",
            " to\n",
            " hike\n",
            " the\n",
            " Bright\n",
            " Golden\n",
            " Gate\n",
            " Bridge\n",
            " (\n",
            "I\n",
            " think\n",
            " that\n",
            "'s\n",
            " the\n",
            " name\n",
            " of\n",
            " the\n",
            " trail\n",
            ")\n",
            " in\n",
            " the\n",
            " Grand\n",
            " Canyon\n",
            ".\n",
            " I\n",
            "'ve\n",
            " been\n",
            " hiking\n",
            "(\"I'm going to arizona to see the Grand Canyon, and I'm planning to hike the \"\n",
            " \"Bright Golden Gate Bridge (I think that's the name of the trail) in the \"\n",
            " \"Grand Canyon. I've been hiking\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm going to arizona to see the Grand Canyon, and I'm planning to hike the Bright Golden Gate Bridge (I think that's the name of the trail) in the Grand Canyon. I've been hiking\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.apply_steering_operator(tlen=34,new_text=\"I'm going to arizona to see the\", lsplit = 22, lambda_w=0.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "KoRAnZFh1qWu",
        "outputId": "d1f41b8c-51a4-4a0e-ec06-5f36612df0c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Grand\n",
            " Canyon\n",
            ".\n",
            " I\n",
            "'ve\n",
            " heard\n",
            " it\n",
            "'s\n",
            " a\n",
            " must\n",
            " see\n",
            ".\n",
            " I\n",
            "'ve\n",
            " also\n",
            " heard\n",
            " it\n",
            "'s\n",
            " a\n",
            " bit\n",
            " of\n",
            " a\n",
            " trek\n",
            " to\n",
            " get\n",
            " there\n",
            ".\n",
            " Is\n",
            " that\n",
            " true\n",
            "?\n",
            "Yes\n",
            ",\n",
            " the\n",
            "(\"I'm going to arizona to see the Grand Canyon. I've heard it's a must see. \"\n",
            " \"I've also heard it's a bit of a trek to get there. Is that true?\\n\"\n",
            " 'Yes, the')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm going to arizona to see the Grand Canyon. I've heard it's a must see. I've also heard it's a bit of a trek to get there. Is that true?\\nYes, the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}
